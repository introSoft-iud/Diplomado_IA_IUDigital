{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#diplomado-en-construccion-de-aplicaciones-asistidas-por-ia","title":"Diplomado en construcci\u00f3n de Aplicaciones Asistidas por IA","text":"<p>Bienvenidos al diploma en construcci\u00f3n de aplicaciones asistidas por modelos de lenguaje de la IUDigital de Antioquia</p> <p>Aunque la inteligencia artificial ha existido como un campo exitoso y prometedor entre los expertos durante varias d\u00e9cadas, la llegada de capacidades computacionales m\u00e1s avanzadas \u2014ofrecidas por las GPU modernas\u2014 y las habilidades demostradas con el lanzamiento de ChatGPT fueron una gran sorpresa para muchos.</p> <p>No est\u00e1 del todo claro c\u00f3mo este \"peque\u00f1o\" avance en la escala de los modelos pudo desencadenar la gran cantidad de aplicaciones asistidas por IA que estamos viendo explotar cada semana. Lo que s\u00ed es claro es que el campo de la ingenier\u00eda de software est\u00e1 siendo revolucionado, y que el nuevo paradigma de construcci\u00f3n de software ya no consiste en los tradicionales flujos de ejecuci\u00f3n, sino que la nueva ingenier\u00eda de sistemas debe integrar a los LLMs en dichos flujos.</p> <p>Hemos dise\u00f1ado este diplomado para introducirte a este nuevo paradigma. </p>"},{"location":"#resultados-de-aprendizage","title":"Resultados de Aprendizage","text":""},{"location":"#pregunta-orientadora","title":"Pregunta Orientadora","text":""},{"location":"#mapa-del-curso","title":"Mapa del curso","text":"<p>crea a aqu\u00ed el mapa del curso</p>"},{"location":"#cronograma-de-actividades","title":"Cronograma de actividades","text":"Actividad de aprendizaje Evidencia de aprendizaje Semana Ponderaci\u00f3n Caracter\u00edsticas principales del reino Fungi Actividad de conocimientos previos Semana 1 10 % Principios de la teor\u00eda del aprendizaje Mapa mental sobre teor\u00eda del aprendizaje Semana 2 20 % Agrega aqu\u00ed otra actividad si aplica Agrega aqu\u00ed otra evidencia Semana % Agrega aqu\u00ed otra actividad si aplica Agrega aqu\u00ed otra evidencia Semana % Agrega aqu\u00ed otra actividad si aplica Agrega aqu\u00ed otra evidencia Semana % Total 100 %"},{"location":"#actividad-de-refuerzo","title":"Actividad de refuerzo","text":"<p>Agrega el nombre de la actividad de refuerzo (cuando as\u00ed se requiera).</p>"},{"location":"Unidad%201/","title":"Index","text":""},{"location":"Unidad%201/#unidad-1-introduccion-a-la-construccion-de-aplicaciones-con-llms","title":"Unidad 1. Introducci\u00f3n a la construcci\u00f3n de aplicaciones con LLMs","text":""},{"location":"Unidad%201/#introduccion-a-la-unidad","title":"Introducci\u00f3n a la unidad","text":"<p>Bienvenidos a la primera unidad. En esta unidad aprender\u00e1s, de manera general, c\u00f3mo funciona un modelo de lenguaje. Comenzaremos usando la API de OpenAI y exploraremos c\u00f3mo conectar sus servicios con nuestras aplicaciones. Luego aprender\u00e1s a utilizar esta misma API a trav\u00e9s del framework LangChain.</p> <p>Finalmente, introduciremos los aspectos fundamentales de la interacci\u00f3n con los LLMs usando LangChain: prompts, templates y output parsers.</p> <p>Como actividad pr\u00e1ctica, elaborar\u00e1s un sistema asistido por IA para extraer datos de comentarios de usuarios en un e-commerce.</p> <p>\u00a1Comencemos!</p>"},{"location":"Unidad%201/#resultados-de-aprendizaje","title":"Resultados de aprendizaje","text":""},{"location":"Unidad%201/#cronograma-de-actividades-de-la-unidad","title":"Cronograma de actividades de la unidad","text":""},{"location":"Unidad%201/#cronograma-de-actividades-unidad-1","title":"Cronograma de actividades - Unidad 1","text":"Actividad de aprendizaje Evidencia de aprendizaje Semana Ponderaci\u00f3n Actividades de aprendizaje 1 y 2 EA1 Semana 1 y 2 25% Total 25 %"},{"location":"Unidad%201/#que-es-un-modelo-de-lenguaje","title":"\u00bfQu\u00e9 es un modelo de lenguaje?","text":"<p>Un modelo de lenguaje es un sistema basado en deep learning que encapsula informaci\u00f3n sobre uno o varios lenguajes. Este sistema es entrenado para predecir qu\u00e9 tan probable es que una palabra aparezca en un determinado contexto.</p> <p>Por ejemplo, dado el contexto:</p> <p>\"Mi plato favorito es el ____\"</p> <p>un modelo de lenguaje que codifique el espa\u00f1ol de Antioquia podr\u00eda predecir \"sancocho\" con m\u00e1s frecuencia que \"ajiaco\".</p>"},{"location":"Unidad%201/#tokens","title":"Tokens","text":"<p>La unidad b\u00e1sica de predicci\u00f3n de un modelo de lenguaje es el token, y el tokenizador es el software que utiliza el modelo para dividir los textos en tokens.</p> <p>Por ejemplo, el tokenizador de GPT-4 divide la frase:</p> <p>\"El sol est\u00e1 brillando intensamente\"</p> <p>de la siguiente manera:</p> Divisi\u00f3n en tokens de una frase utilizando el tokenizador de GPT-4. Fuente: OpenAI Tokenizer. <p>Para tener en cuenta</p> <p>Hay varias razones por las que los modelos de lenguaje utilizan tokens en lugar de palabras completas o caracteres individuales.</p> <p>A diferencia de un simple car\u00e1cter, un token permite dividir una palabra en componentes con significado propio. Por ejemplo, la palabra \"intensamente\" puede ser dividida por el tokenizador en \"intens\" y \"amente\", y cada uno de estos componentes aporta parte del significado de la palabra completa.</p> <p>Esto tambi\u00e9n implica que hay menos tokens \u00fanicos que palabras \u00fanicas, lo que hace que el vocabulario del modelo sea m\u00e1s peque\u00f1o y, por lo tanto, m\u00e1s eficiente.</p> <p>Finalmente, los tokens permiten al modelo entender palabras desconocidas. Por ejemplo, si se le presenta la palabra \"WhatsAppeando\", el modelo puede inferir su significado a partir del contexto en que aparecen los tokens \"WhatsApp\" y \"ando\".</p>"},{"location":"Unidad%201/#que-son-los-grandes-modelos-de-lenguaje-llm","title":"\u00bfQu\u00e9 son los grandes modelos de lenguaje (LLM)?","text":"<p>Lo que diferencia un LLM (Large Language Model) de un modelo de lenguaje tradicional es el n\u00famero de par\u00e1metros. Los par\u00e1metros son los pesos que el modelo ajusta durante el proceso de entrenamiento, y que determinan c\u00f3mo interpreta y genera texto a partir de los datos.</p> <p>Por supuesto, el concepto de \"grande\" es relativo. \u00bfA partir de cu\u00e1ntos par\u00e1metros puede considerarse que un modelo es grande? Ve\u00e1moslo as\u00ed:</p> <ul> <li>El GPT lanzado por OpenAI en 2018 ten\u00eda 117 millones de par\u00e1metros, y ya era considerado un modelo grande en su \u00e9poca.</li> <li>En 2019, GPT-2 aument\u00f3 ese n\u00famero a 1.5 billones de par\u00e1metros.</li> <li>Hasta abril de 2025, el modelo de lenguaje m\u00e1s grande conocido p\u00fablicamente es GPT-4 de OpenAI, con aproximadamente 1.76 billones de par\u00e1metros.</li> </ul> <p>Es muy posible que en el futuro estos modelos hoy considerados LLMs sean vistos como simples modelos de lenguaje, a medida que la tecnolog\u00eda y los recursos computacionales avancen.</p> <p>Es muy posible que en el futuro estos modelos hoy considerados LLMs sean vistos como simples modelos de lenguaje, a medida que la tecnolog\u00eda y los recursos computacionales avancen.</p> <p>Para tener en cuenta</p> <p>El crecimiento en la cantidad de par\u00e1metros no garantiza una mejora si no hay suficientes datos disponibles para el entrenamiento. Entrenar un modelo grande con un conjunto de datos peque\u00f1o puede causar sobreajuste (overfitting), lo que significa que el modelo funciona bien con los datos de entrenamiento pero falla al generalizar a nuevos datos. Esto no solo desperdicia recursos computacionales, sino que tambi\u00e9n produce un modelo con poca utilidad pr\u00e1ctica.</p> <p>Cuando no se cuenta con grandes vol\u00famenes de datos, se pueden aplicar t\u00e9cnicas como:</p> <ul> <li> <p>Aprendizaje por transferencia (transfer learning)   Utiliza modelos previamente entrenados para resolver nuevas tareas con pocos datos.</p> </li> <li> <p>Aumento de datos (data augmentation)   Genera versiones modificadas de los datos existentes para enriquecer el conjunto de entrenamiento.</p> </li> <li> <p>Destilaci\u00f3n de conocimiento (knowledge distillation)   Transfiere el conocimiento de un modelo grande (profesor) a uno m\u00e1s peque\u00f1o (estudiante) manteniendo un rendimiento competitivo.</p> </li> </ul> <p>Estas estrategias permiten que modelos m\u00e1s peque\u00f1os logren mejor desempe\u00f1o, aprovechando conocimiento preexistente o la generaci\u00f3n sint\u00e9tica de datos.</p>"},{"location":"Unidad%201/#de-ml-igeniringa-a-ia-ingering","title":"De ML Igeniringa a IA Ingering","text":"<p>Para tener en cuenta</p> <p>Aseg\u00farate de evaluar los posibles sesgos en los datos antes de implementar un modelo de IA. Los sesgos no detectados pueden llevar a decisiones injustas, afectando la equidad y la confianza en la tecnolog\u00eda.</p> <p>\ud83d\udcd6 Para aprender m\u00e1s</p> <p>Si deseas conocer m\u00e1s sobre [tema], lee el siguiente material: Art\u00edculo de [nombre del art\u00edculo]: URL: [enlace]</p> <ul> <li> Video: Oportunidades en IA Autor: Andrew Ng   Para obtener una visi\u00f3n sobre el panorama actual de la inteligencia artificial, te invito a que veas la conferencia del profesor Andrew Ng Oportunidades en IA. Ver Video</li> </ul> <ul> <li> Sabias que Autor: Andrew Ng   Para obtener una visi\u00f3n sobre el panorama actual de la inteligencia artificial, te invito a que veas la conferencia del profesor Andrew Ng Oportunidades en IA. Ver Video</li> </ul> <ul> <li> Reto formativo Plantemiento:   Para obtener una visi\u00f3n sobre el panorama actual de la inteligencia artificial, te invito a que veas la conferencia del profesor Andrew Ng Oportunidades en IA. Ver Video</li> </ul> <ul> <li> Recurso formativo Plantemiento:   Para obtener una visi\u00f3n sobre el panorama actual de la inteligencia artificial, te invito a que veas la conferencia del profesor Andrew Ng Oportunidades en IA. Ver Video</li> </ul>"}]}